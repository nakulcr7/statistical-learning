}
# Chunk 15
obervation_density_estimate <- function(observation, c) {
result <- 1
for(feature_name in names(observation)) {
result <- result * feature_density_estimate(feature_name, observation[feature_name], c)
}
return(result)
}
# Chunk 16
prior_prob <- function(c) {
return(saheart_training %>% filter(chd == c) %>% nrow() / nrow(saheart_training))
}
naive_bayes_prob <- function(observation, c) {
likelihood <- prior_prob(c) * obervation_density_estimate(observation, c)
support <- prior_prob(1) * obervation_density_estimate(observation, 1) +
prior_prob(0) * obervation_density_estimate(observation, 0)
if(support == 0) {
return(0)
}
else {
return(likelihood / support)
}
}
# Chunk 17
naive_bayes_predict <- function(observation) {
prob.zero <- naive_bayes_prob(observation, 0)
prob.one <- naive_bayes_prob(observation, 1)
if(prob.one > prob.zero) {
return(1)
}
else {
return(0)
}
}
# Chunk 18
naive_bayes_performance <- function(observations, actual_y) {
true_positive <- 0
for(i in 1:nrow(observations)) {
if (naive_bayes_predict(observations[i, ]) == actual_y[i]) {
true_positive = true_positive + 1
}
}
return(true_positive / nrow(observations))
}
result <- naive_bayes_performance(saheart_validation %>% dplyr::select_(.dots = cont_features), saheart_validation %>% pull(chd))
cat("Accuracy of Naive Bayes Classifier: ", result)
library(MASS)
lda.fit <- lda(chd~sbp + tobacco + ldl + adiposity + typea + obesity + alcohol + age, data = saheart_training)
lda.fit
lda.pred <- predict(lda.fit, saheart_validation)#$posterior[,2]
lda.pred
lda.pred <- predict(lda.fit, saheart_validation)$posterior[,2]
lda.pred
library(ROCR)
lda.pred <- prediction(lda.pred.valid, saheart_validation$chd)
lda.pred <- prediction(lda.pred, saheart_validation$chd)
lda.pred
lda.perf <- performance(lda.pred, "tpr", "fpr")
plot(lda.perf, colorize=F, main="Validation - LDA")
cat("Area ", unlist(attributes(performance(lda.perf, "auc"))$y.values))
cat("Area ", unlist(attributes(performance(lda.pred, "auc"))$y.values))
lda.pred
table(lda.pred, saheart_validation$chd)
svm.radial.tune <- tune(svm, chd~., data = saheart_training, kernel = "radial",
ranges = list(cost = c(0.1, 1, 10, 100, 1000)),
gamma = c(0.5, 1, 2, 3, 4))
svm.radial.best <- svm.radial.tune$best.model
summary(svm.radial.best)
svm.radial.best <- svm.radial.tune$best.model
summary(svm.radial.best)
svm.radial.tune
?svm
is.factor(saheart_training$chd)
data
svm.radial.tune <- tune(svm, chd~., data = saheart_training, kernel = "radial",
ranges = list(cost = c(0.1, 1, 10, 100, 1000)),
gamma = c(0.5, 1, 2, 3, 4))
summary(svm.radial.tune)
svm
?sv,
svm.radial.tune <- tune(svm, chd~., data = saheart_training, kernel = "radial",
gamma = list(0.5, 1, 2, 3, 4),
ranges = list(cost = c(0.1, 1, 10, 100, 1000)))
summary(svm.radial.tune)
svm.radial.best <- svm.radial.tune$best.model
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = '>')
setwd("~/Workspace/northeastern/cs6140/hw4/")
# Chunk 2
x = -2:2
y = c(1 + 0 + 0,
1 + 0 + 0,
1 + 1 + 0,
1 + (1-0) + 0,
1 + (1-1) + 0)
plot(x, y, type = "o", col = "blue")
# Chunk 3
x1 = c(3, 2, 4, 1, 2, 4, 4)
x2 = c(4, 2, 4, 4, 1, 3, 1)
y = append(rep("red", 4), rep("blue", 3))
plot(x1, x2, col = y, xlim = c(0, 5), ylim = c(0, 5), xlab = "X1", ylab = "X2")
# Chunk 4
plot(x1, x2, col = y, xlim = c(0, 5), ylim = c(0, 5), xlab = "X1", ylab = "X2")
abline(-0.5, 1)
# Chunk 5
plot(x1, x2, col = y, xlim = c(0, 5), ylim = c(0, 5), xlab = "X1", ylab = "X2")
abline(-0.5, 1)
abline(-1, 1, lty = 2)
abline(0, 1, lty = 2)
# Chunk 6
plot(x1, x2, col = y, xlim = c(0, 5), ylim = c(0, 5), xlab = "X1", ylab = "X2")
abline(-0.5, 1)
arrows(4, 4, 4, 3.5)
arrows(4, 3, 4, 3.5)
arrows(2, 1, 2, 1.5)
arrows(2, 2, 2, 1.5)
# Chunk 7
plot(x1, x2, col = y, xlim = c(0, 5), ylim = c(0, 5), xlab = "X1", ylab = "X2")
abline(-0.2, 1)
# Chunk 8
x1 <- c(x1, 3)
x2 <- c(x2, 1)
y <- c(y, "red")
plot(x1, x2, col = y, xlim = c(0, 5), ylim = c(0, 5), xlab = "X1", ylab = "X2")
# Chunk 9
# Imports
library(dplyr)
rm(list=ls())
set.seed(123)
# Read the data
saheart <- read.table("SAheart.txt", sep = ",", header = TRUE) %>% dplyr::select(-row.names)
dim(saheart)
# Chunk 10
levels(saheart$famhist)
# Chunk 11
# Categorial to numeric
levels(saheart$famhist) <- c(0, 1)
saheart$famhist <- as.character(saheart$famhist)
saheart$famhist <- as.numeric(saheart$famhist)
saheart$chd <- as.factor(saheart$chd)
# Split dataset
ratio <- sample(1:nrow(saheart), 231)
saheart_training <- saheart[ratio, ]
saheart_validation <- saheart[-ratio, ]
# Chunk 12
cont_features <- names(saheart_training %>% dplyr::select(-famhist, -chd))
densities.zero <- list()
densities.one <- list()
for(i in 1:length(cont_features)) {
densities.zero[[i]] <- density(saheart_training %>% filter(chd==0) %>% pull(cont_features[i]),
kernel = "gaussian", bw = "ucv")
densities.one[[i]] <- density(saheart_training %>% filter(chd==1) %>% pull(cont_features[i]),
kernel = "gaussian", bw = "ucv")
}
# Chunk 13
for(i in 1:length(cont_features)) {
plot(densities.one[[i]])
plot(densities.zero[[i]])
}
# Chunk 14
feature_density_estimate_helper <- function(density, feature_val) {
step_size <- density$x[2] - density$x[1]
index <- as.integer((feature_val - density$x[1]) / step_size)
if(index > 1 & index <= 512) {
return(density$y[index])
}
else {
return(0)
}
}
feature_density_estimate <- function(feature_name, feature_value, c) {
result <- 0
if (c == 1) {
result <- feature_density_estimate_helper(densities.one[[which(cont_features==feature_name)]],
feature_value)
}
else {
result <- feature_density_estimate_helper(densities.zero[[which(cont_features==feature_name)]],
feature_value)
}
return(result)
}
# Chunk 15
obervation_density_estimate <- function(observation, c) {
result <- 1
for(feature_name in names(observation)) {
result <- result * feature_density_estimate(feature_name, observation[feature_name], c)
}
return(result)
}
# Chunk 16
prior_prob <- function(c) {
return(saheart_training %>% filter(chd == c) %>% nrow() / nrow(saheart_training))
}
naive_bayes_prob <- function(observation, c) {
likelihood <- prior_prob(c) * obervation_density_estimate(observation, c)
support <- prior_prob(1) * obervation_density_estimate(observation, 1) +
prior_prob(0) * obervation_density_estimate(observation, 0)
if(support == 0) {
return(0)
}
else {
return(likelihood / support)
}
}
# Chunk 17
naive_bayes_predict <- function(observation) {
prob.zero <- naive_bayes_prob(observation, 0)
prob.one <- naive_bayes_prob(observation, 1)
if(prob.one > prob.zero) {
return(1)
}
else {
return(0)
}
}
# Chunk 18
naive_bayes_performance <- function(observations, actual_y) {
true_positive <- 0
for(i in 1:nrow(observations)) {
if (naive_bayes_predict(observations[i, ]) == actual_y[i]) {
true_positive = true_positive + 1
}
}
return(true_positive / nrow(observations))
}
result <- naive_bayes_performance(saheart_validation %>% dplyr::select_(.dots = cont_features),
saheart_validation %>% pull(chd))
cat("Accuracy of Naive Bayes Classifier: ", result)
# Chunk 19
library(MASS)
library(ROCR)
lda.fit <- lda(chd~sbp + tobacco + ldl + adiposity + typea + obesity + alcohol + age,
data = saheart_training)
lda.pred <- predict(lda.fit, saheart_validation)$posterior[,2]
lda.pred <- prediction(lda.pred, saheart_validation$chd)
lda.perf <- performance(lda.pred, "tpr", "fpr")
plot(lda.perf, colorize=F, main="Validation - LDA")
# Area
cat("Accuracy of LDA: ", unlist(attributes(performance(lda.pred, "auc"))$y.values))
# Chunk 20
# Import
library(e1071)
svm.linear.tune <- tune(svm, chd~., data = saheart_training, kernel = "linear",
ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
svm.linear.best <- svm.linear.tune$best.model
summary(svm.linear.best)
svm.linear.pred <- predict(svm.linear.best, saheart_validation)
svm.linear.result <- table(svm.linear.pred, saheart_validation$chd)
cat("Accuracy of Support Vector Classifier: ", sum(diag(svm.linear.result)) / sum(svm.linear.result))
svm.radial.tune <- tune(svm, chd~., data = saheart_training, kernel = "radial",
gamma = list(0.5, 1, 2, 3, 4),
ranges = list(cost = c(0.1, 1, 10, 100, 1000)))
svm.radial.best <- svm.radial.tune$best.model
summary(svm.radial.best)
svm.radial.pred <- predict(svm.radial.best, saheart_validation)
svm.radial.result <- table(svm.radial.pred, saheart_validation$chd)
cat("Accuracy of Support Vector Machine: ", sum(diag(svm.radial.result)) / sum(svm.radial.result))
svm.radial.tune <- tune(svm, chd~., data = saheart_training, kernel = "radial",
gamma = list(0.5, 1, 2, 3, 4),
ranges = list(cost = c(0.1, 1, 10, 100, 1000)))
svm.radial.best <- svm.radial.tune$best.model
summary(svm.radial.best)
svm.radial.tune <- tune(svm, chd~., data = saheart_training, kernel = "radial",
gamma = c(0.5, 1, 2, 3, 4),
ranges = list(cost = c(0.1, 1, 10, 100, 1000)))
svm.radial.best <- svm.radial.tune$best.model
summary(svm.radial.best)
summary(svm.radial.best)
svm.radial.pred <- predict(svm.radial.best, saheart_validation)
svm.radial.result <- table(svm.radial.pred, saheart_validation$chd)
cat("Accuracy of Support Vector Machine: ", sum(diag(svm.radial.result)) / sum(svm.radial.result))
lda.pred
library(ROCR)
lda.fit <- lda(chd~sbp + tobacco + ldl + adiposity + typea + obesity + alcohol + age,
data = saheart_training)
lda.pred <- predict(lda.fit, saheart_validation)$posterior[,2]
?lda.pred
lda.fit <- lda(chd~sbp + tobacco + ldl + adiposity + typea + obesity + alcohol + age,
data = saheart_training)
summary(lda.fit)
temp <- predict(lda.fit)
temp
temp <- as.numeric(temp$class) - 1
temp
lda.fit <- lda(chd~sbp + tobacco + ldl + adiposity + typea + obesity + alcohol + age,
data = saheart_training)
lda.pred <- predict(lda.fit, saheart_validation)$posterior[,2]
lda.pred
names(lda.pred)
lda.pred <- predict(lda.fit, saheart_validation, type="response")#$posterior[,2]
lda.pred
names(lda.pred)
lda.pred$class
as.numeric(lda.pred$class)
as.numeric(lda.pred$class) - 1
lda.pred <- as.numeric(lda.pred$class) - 1
lda.pred
pre_accu<-1-sum(abs(lda.pred-saheart_validation$chd))/length(saheart_validation$chd)
pre_accu<-1-sum(abs(lda.pred - as.numeric(saheart_validation$chd))/length(saheart_validation$chd)
)
pre_accu
lda.pred
length(lda.pred)
lda.pred[1]
f <- function(actual, predicted) {
correct <- 0
for(i in 1:length(actual)) {
if(actual[i] == predicted[i]) {
correct = correct + 1
}
}
return(correct / length(predicted))
}
library(MASS)
library(ROCR)
lda.fit <- lda(chd~sbp + tobacco + ldl + adiposity + typea + obesity + alcohol + age,
data = saheart_training)
lda.pred <- predict(lda.fit, saheart_validation, type="response")#$posterior[,2]
lda_pred<-as.numeric(lda.pred$class)-1
lda_pred
print(f(as.numeric(saheart_validation$chd), lda.pred))
library(MASS)
library(ROCR)
lda.fit <- lda(chd~sbp + tobacco + ldl + adiposity + typea + obesity + alcohol + age,
data = saheart_training)
saheart_validation[,-10]
lda_predict <- predict(lda.fit,saheart_validation[,-10],type="response")
lda_predict <- as.numeric(lda_predict$class)-1
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = '>')
setwd("~/Workspace/northeastern/cs6140/hw4/")
# Chunk 2
x = -2:2
y = c(1 + 0 + 0,
1 + 0 + 0,
1 + 1 + 0,
1 + (1-0) + 0,
1 + (1-1) + 0)
plot(x, y, type = "o", col = "blue")
# Chunk 3
x1 = c(3, 2, 4, 1, 2, 4, 4)
x2 = c(4, 2, 4, 4, 1, 3, 1)
y = append(rep("red", 4), rep("blue", 3))
plot(x1, x2, col = y, xlim = c(0, 5), ylim = c(0, 5), xlab = "X1", ylab = "X2")
# Chunk 4
plot(x1, x2, col = y, xlim = c(0, 5), ylim = c(0, 5), xlab = "X1", ylab = "X2")
abline(-0.5, 1)
# Chunk 5
plot(x1, x2, col = y, xlim = c(0, 5), ylim = c(0, 5), xlab = "X1", ylab = "X2")
abline(-0.5, 1)
abline(-1, 1, lty = 2)
abline(0, 1, lty = 2)
# Chunk 6
plot(x1, x2, col = y, xlim = c(0, 5), ylim = c(0, 5), xlab = "X1", ylab = "X2")
abline(-0.5, 1)
arrows(4, 4, 4, 3.5)
arrows(4, 3, 4, 3.5)
arrows(2, 1, 2, 1.5)
arrows(2, 2, 2, 1.5)
# Chunk 7
plot(x1, x2, col = y, xlim = c(0, 5), ylim = c(0, 5), xlab = "X1", ylab = "X2")
abline(-0.2, 1)
# Chunk 8
x1 <- c(x1, 3)
x2 <- c(x2, 1)
y <- c(y, "red")
plot(x1, x2, col = y, xlim = c(0, 5), ylim = c(0, 5), xlab = "X1", ylab = "X2")
# Chunk 9
# Imports
library(dplyr)
rm(list=ls())
set.seed(123)
# Read the data
saheart <- read.table("SAheart.txt", sep = ",", header = TRUE) %>% dplyr::select(-row.names)
dim(saheart)
# Chunk 10
levels(saheart$famhist)
# Chunk 11
# Categorial to numeric
levels(saheart$famhist) <- c(0, 1)
saheart$famhist <- as.character(saheart$famhist)
saheart$famhist <- as.numeric(saheart$famhist)
saheart$chd <- as.factor(saheart$chd)
# Split dataset
ratio <- sample(1:nrow(saheart), 231)
saheart_training <- saheart[ratio, ]
saheart_validation <- saheart[-ratio, ]
# Chunk 12
cont_features <- names(saheart_training %>% dplyr::select(-famhist, -chd))
densities.zero <- list()
densities.one <- list()
for(i in 1:length(cont_features)) {
densities.zero[[i]] <- density(saheart_training %>% filter(chd==0) %>% pull(cont_features[i]),
kernel = "gaussian", bw = "ucv")
densities.one[[i]] <- density(saheart_training %>% filter(chd==1) %>% pull(cont_features[i]),
kernel = "gaussian", bw = "ucv")
}
# Chunk 13
for(i in 1:length(cont_features)) {
plot(densities.one[[i]])
plot(densities.zero[[i]])
}
# Chunk 14
feature_density_estimate_helper <- function(density, feature_val) {
step_size <- density$x[2] - density$x[1]
index <- as.integer((feature_val - density$x[1]) / step_size)
if(index > 1 & index <= 512) {
return(density$y[index])
}
else {
return(0)
}
}
feature_density_estimate <- function(feature_name, feature_value, c) {
result <- 0
if (c == 1) {
result <- feature_density_estimate_helper(densities.one[[which(cont_features==feature_name)]],
feature_value)
}
else {
result <- feature_density_estimate_helper(densities.zero[[which(cont_features==feature_name)]],
feature_value)
}
return(result)
}
# Chunk 15
obervation_density_estimate <- function(observation, c) {
result <- 1
for(feature_name in names(observation)) {
result <- result * feature_density_estimate(feature_name, observation[feature_name], c)
}
return(result)
}
# Chunk 16
prior_prob <- function(c) {
return(saheart_training %>% filter(chd == c) %>% nrow() / nrow(saheart_training))
}
naive_bayes_prob <- function(observation, c) {
likelihood <- prior_prob(c) * obervation_density_estimate(observation, c)
support <- prior_prob(1) * obervation_density_estimate(observation, 1) +
prior_prob(0) * obervation_density_estimate(observation, 0)
if(support == 0) {
return(0)
}
else {
return(likelihood / support)
}
}
# Chunk 17
naive_bayes_predict <- function(observation) {
prob.zero <- naive_bayes_prob(observation, 0)
prob.one <- naive_bayes_prob(observation, 1)
if(prob.one > prob.zero) {
return(1)
}
else {
return(0)
}
}
# Chunk 18
naive_bayes_performance <- function(observations, actual_y) {
true_positive <- 0
for(i in 1:nrow(observations)) {
if (naive_bayes_predict(observations[i, ]) == actual_y[i]) {
true_positive = true_positive + 1
}
}
return(true_positive / nrow(observations))
}
result <- naive_bayes_performance(saheart_validation %>% dplyr::select_(.dots = cont_features),
saheart_validation %>% pull(chd))
cat("Accuracy of Naive Bayes Classifier: ", result)
library(MASS)
lda.fit <- lda(chd~sbp + tobacco + ldl + adiposity + typea + obesity + alcohol + age,
data = saheart_training)
lda_predict <- predict(lda.fit,saheart_validation[,-10],type="response")
lda_predict <- as.numeric(lda_predict$class)-1
accu <- 1-sum(abs(lda_predict-saheart_validation[,10]))/length(saheart_validation[,10])
accu <- 1-sum(abs(lda_predict-saheart_validation[,10]))/length(as.numeric(saheart_validation[,10]))
accu <- 1-sum(abs(lda_predict-as.numeric(saheart_validation[,10])))/length(as.numeric(saheart_validation[,10]))
cat("Accuracy is " , accu*100, "%")
saheart_validation[,10]
as.numeric(saheart_validation[,10])
lda_predict <- predict(lda.fit,saheart_validation[,-10],type="response")
lda_predict <- as.numeric(lda_predict$class)-1
actual <- as.numeric(saheart_validation[,10]) - 1
accu <- 1-sum(abs(lda_predict - actual)) / length(actual)
cat("Accuracy is " , accu*100, "%")
f <- function(actual, predicted) {
correct <- 0
for(i in 1:length(actual)) {
if(actual[i] == predicted[i]) {
correct = correct + 1
}
}
return(correct / length(predicted))
}
library(MASS)
lda.fit <- lda(chd~sbp + tobacco + ldl + adiposity + typea + obesity + alcohol + age,
data = saheart_training)
# lda.pred <- predict(lda.fit, saheart_validation, type="response")#$posterior[,2]
# lda_pred<-as.numeric(lda.pred$class)-1
# print(f(as.numeric(saheart_validation$chd), lda.pred))
lda_predict <- predict(lda.fit,saheart_validation[,-10],type="response")
lda_predict <- as.numeric(lda_predict$class)-1
actual <- as.numeric(saheart_validation[,10]) - 1
accu <- 1-sum(abs(lda_predict - actual)) / length(actual)
cat("Accuracy of LDA: " , accu)
